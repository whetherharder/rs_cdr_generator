# Performance Optimisation Implementation Plan

В документе описаны шаги по внедрению оптимизаций, выявленных в последнем перфоманс‑ревью. План разбит на независимые блоки, чтобы их можно было выполнять по отдельности или параллельно.

---

## 1. Ускорение доступа к redb (`SubscriberDbRedb::get_subscriber_at`)

**Проблема:** каждый вызов открывает read-транзакцию, повторно открывает таблицу и десериализует весь вектор снапшотов. В `worker_generate_redb_chunked` это происходит дважды на каждое событие (для MO и MT), что даёт квадратичный рост времени и сильную нагрузку на дисковый кэш.

**Шаги реализации**

1. Добавить новый тип `SnapshotCache { msisdn: u64, snapshots: Arc<Vec<SubscriberSnapshotNumeric>> }` и вспомогательный метод `SubscriberDbRedb::get_or_load_cache(range)`, который:
   - открывает одну read-транзакцию на весь диапазон,
   - читает данные через `table.range` (как в `load_chunk`) и сортирует снапшоты по `valid_from`.
2. В `worker_generate_redb_chunked`:
   - перед циклом по подписчикам вызвать `get_or_load_cache` для текущего диапазона,
   - построить `HashMap<u64, Arc<Vec<...>>>` для O(1) доступа к списку снапшотов,
   - заменить вызовы `get_subscriber_at` на локальный поиск по вектору (бинарный поиск по `valid_from`/`valid_to`).
3. Для MT-корреляции использовать тот же кэш, а для MSISDN вне диапазона работников — fallback к старому API (можно оставить `get_subscriber_at` для редких случаев).
4. Добавить unit-тесты на новый метод + бенч (criterion или `cargo bench`) для сравнения «до/после».

**Возможные сложности и управление рисками**

- Избежать роста памяти: ограничить размер кэша (LRU на уровне воркера) и очищать его на границах чанков.
- Следить за безопасностью многопоточности: воркеры уже используют thread-local данные, поэтому кэш должен жить внутри воркера и не делиться между потоками.

**Валидация**

- Запустить `bench_test`/`benchmark.sh` на 10k/100k подписчиков и сравнить длительность шага «redb chunked».
- Проверить профайлером (flamegraph или `perf`) снижение времени в `SubscriberDbRedb::get_subscriber_at`.

---

## 2. Предварительная подготовка распределений контактов (`WeightedIndex`)

**Проблема:** в `worker_generate` для каждого пользователя заново создаётся `WeightedIndex`, что тратит O(n_contacts) на каждый вызов.

**Шаги реализации**

1. В `identity::Contacts` добавить поле `dist: Option<WeightedIndex<f64>>`.
2. В `build_contacts` вычислить `WeightedIndex::new` один раз и сохранить в структуру; вероятности хранить как `Arc<[f64]>`, чтобы избежать лишних копий.
3. В генераторе заменить локальное создание `WeightedIndex::new(c_probs)` на использование уже подготовленного `Contacts::dist`.
4. Добавить бенч «contact sampling» (можно criterion) и unit-тест, что распределение корректно сериализуется/клонится.

**Валидация**

- Запустить синтетический тест на 100k подписчиков и убедиться, что время генерации падает, а частота выпадения контактов совпадает с исходной (можно сравнить статистику из `stats_shard*.json`).

---

## 3. Избавление от `format!/parse` в горячих путях

**Проблема:** в chunked-пути каждое построение MSISDN делает `format!("{}{:07}", …).parse::<u64>()`, что вызывает аллокации и парсинг.

**Шаги реализации**

1. В начале `worker_generate_redb_chunked` создать `numeric_prefixes: Vec<u64>` (аналогично non-DB ветке).
2. Заменить все места с `format!(...).parse()` на арифметику `prefix * 10_000_000 + number`.
3. Добавить helper-функцию `fn compose_msisdn(prefix: u64, number: u64) -> u64`, чтобы избежать дублирования.

**Валидация**

- Профайлер `perf`/`flamegraph` должен показать исчезновение `core::fmt` и `core::num::parse` из горячего стека.
- Сравнить генерацию 1M записей до/после; ожидаем выигрыш ~5-10%.

---

## 4. Повторное использование распределений (`LogNormal`, `Normal`)

**Проблема:** `sample_call_duration` и ветка `sample_poisson(mean >= 30)` каждый раз создают новое распределение.

**Шаги реализации**

1. В `CallGenerator` сохранить `LogNormal` как поле (`duration_dist`). Метод `generate` и `generate_forced_direction` используют `self.duration_dist.sample(rng)`.
2. Для `sample_poisson`:
   - Добавить структуру `PoissonSampler { poisson: Option<Poisson<f64>>, normal: Normal<f64>, mean: f64 }`.
   - Держать экземпляр в `Config` или создавать per-worker и передавать внутрь функций как замкнутый объект.
3. Обновить unit-тесты, чтобы они покрывали новые ветки.

**Валидация**

- Criterion-бенч на генерацию 1M call durations.
- Проверить, что распределение длительностей не изменилось (сравнение средних/квантилей на выборке).

---

## 5. Реиспользование потоков записи

**Проблема:** `writer_task` создаёт новый gzip writer для каждой партии, что даёт лишние системные вызовы и дорогие `spawn_blocking`.

**Шаги реализации**

1. Перенести логику из `writer::EventWriter` в async-слой: в `writer_task` держать один `EventWriter` на shard_id.
2. Изменить `WriterMessage` так, чтобы `Batch` содержала только данные, без необходимости вычислять имя файла (номер части должен храниться в `EventWriter`).
3. В `writer_task` обрабатывать `Batch` синхронно (без `spawn_blocking`) — запись идёт через `BufWriter` и не блокирует event loop, т.к. задача и так выполняется в выделенном worker runtime.
4. Обновить тесты `async_writer` и провести регрессивный тест с настройкой `rotate_bytes`, чтобы убедиться, что ротация файлов работает.

**Валидация**

- Сравнить генерацию крупной выборки (например, `bench_config_1m.yaml`) до/после; ожидается снижение числа `spawn_blocking` и системных вызовов.
- Проверить размер и число файлов, убедиться, что ротация происходит корректно.

---

## 6. План тестирования и регрессий

1. Запустить существующие бенчмарки (`benchmark.sh`, `run_redb_benchmarks.sh`) и сохранить результаты в `benchmark_results`.
2. Добавить короткий интеграционный тест (например, `cargo test -- profiles::chunked_redb_smoke`) для проверки генерации в redb-режиме.
3. Использовать `cargo fmt` и `cargo clippy --all-targets` для уверенности в отсутствии регрессий.
4. Обновить `PERFORMANCE_SUMMARY.md` после измерений.

---

## 7. Дорожная карта внедрения

- **Этап 1 (redb + кэш):** 1–2 дня на реализацию + тесты, важен для основного выигрыша.
- **Этап 2 (распределения и форматирование):** 0.5 дня, можно параллелить.
- **Этап 3 (writer):** 1 день, требует аккуратного тестирования ротации.
- **Этап 4 (финальные замеры, документация):** 0.5 дня.

Общий объём — ~3 дня при одном разработчике. После каждого этапа стоит обновлять бенчмарк‑отчёт и фиксировать прирост.

---

## 8. Метрики успеха

- Сокращение времени генерации `1m` конфигурации минимум на 30% в redb-режиме.
- Снижение CPU времени, занятого `SubscriberDbRedb::get_subscriber_at`, минимум в 5 раз (по профилю).
- Уменьшение числа системных вызовов `open/close` на порядок (для writer).

---

Документ можно расширять по мере появления новых гипотез и результатов тестов.
